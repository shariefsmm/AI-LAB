---------Value_Iteration----------
Policy is as follows: 
[[-1. -1. -1. ... -1. -1. -1.]
 [-1. -1. -1. ... -1. -1. -1.]
 [-1. -1. -1. ... -1. -1. -1.]
 ...
 [-1. -1. -1. ... -1. -1. -1.]
 [-1. -1. -1. ... -1. -1. -1.]
 [-1. -1. -1. ... -1. -1. -1.]]
State Value is as follows:
[[-60. -60. -60. ... -37. -37. -37.]
 [-60. -60. -60. ... -37. -37. -37.]
 [-60. -60. -60. ... -36. -36. -36.]
 ...
 [-84. -84. -84. ...   0.   0.   0.]
 [-84. -84. -84. ...   0.   0.   0.]
 [-84. -84. -84. ...   0.   0.   0.]]
---------Policy_Iteration----------
Policy is as follows: 
[[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
State Value is as follows:
[[-10. -10. -10. ... -10. -10. -10.]
 [-11. -11. -11. ... -10. -10. -10.]
 [-11. -11. -11. ... -10. -10. -10.]
 ...
 [-35. -35. -35. ...   0.   0.   0.]
 [-35. -35. -35. ...   0.   0.   0.]
 [-35. -35. -35. ...   0.   0.   0.]]
