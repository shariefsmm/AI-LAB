{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is to define the state space \n",
    "v_n = 100                     #we are going to divide the velocity state space into 1500 discrete points\n",
    "v_max = 0.07\n",
    "v_min = -0.07\n",
    "velocities = np.linspace (v_min , v_max , v_n)\n",
    "\n",
    "p_n = 100\n",
    "p_max = 0.6\n",
    "p_min = -1.2\n",
    "positions = np.linspace (p_min , p_max , p_n)\n",
    "gamma = 0.9\n",
    "reward = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_index (pos , vel):\n",
    "    #this function takes the pos and the vel and then return the correspoding index of the state\n",
    "    #in the state space\n",
    "    v_div = (v_max - v_min) / (v_n - 1)\n",
    "    y =  (vel - v_min) / v_div\n",
    "    \n",
    "    p_div = (p_max - p_min) / (p_n - 1)\n",
    "    x = (pos - p_min) / p_div\n",
    "    \n",
    "    return (int(x) , int(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mountain_car_simulation (pos , vel , action):\n",
    "    new_velocity = vel + (action * 0.001) + math.cos (3 * pos ) * (-0.0025)\n",
    "    #applying the boundary condition\n",
    "\n",
    "    \n",
    "    new_velocity = min (max (v_min , new_velocity) , v_max)\n",
    "    new_position = pos + new_velocity\n",
    "    \n",
    "    \n",
    "    #apply boundary\n",
    "    new_position = min (max (p_min , new_position) , p_max )\n",
    "\n",
    "    if (new_position <= p_min):\n",
    "        new_velocity = 0\n",
    "    #print(\"oldVel = \", vel, \"oldPos = \", pos, \"newVel = \", new_velocity, \"newPos = \", new_position)    \n",
    "    return new_position , new_velocity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6, 0.0015680052367327171)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mountain_car_simulation (0.6 , +0.0, +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration (state_values):\n",
    "    #this function takes the state values (initial)\n",
    "    #and then use the value iteration to return the actual value function of the states\n",
    "    \n",
    "    #in the state values rows represent the position and the columns represent the velocity\n",
    "    action_space = np.zeros ((p_n , v_n))\n",
    "    \n",
    "    threshold = 1000\n",
    "    epsilon = 0.01\n",
    "    threshold_list = []\n",
    "    \n",
    "    for itr in range(1500):\n",
    "        \n",
    "        if (itr % 50 == 0):\n",
    "            print (\"number of iterations : \" , itr)\n",
    "        #print (threshold)\n",
    "        #compute the value function for the first sweep\n",
    "        threshold = -math.inf\n",
    "        \n",
    "        for row in range(p_n):\n",
    "            for col in range(v_n):\n",
    "                \n",
    "                current_vel = velocities[col]\n",
    "                current_pos = positions[row]\n",
    "                \n",
    "                optimal_value = -math.inf\n",
    "                temp_value = -1\n",
    "                for action in [-1 , 0 , 1]:\n",
    "                    \n",
    "                    new_position , new_velocity = mountain_car_simulation(current_pos, current_vel , action)\n",
    "                    x , y = give_index (new_position , new_velocity)\n",
    "                    \n",
    "                    temp_value =state_values[x][y]\n",
    "                    if (new_position < 0.6):\n",
    "                        temp_value += -1\n",
    "                    \n",
    "                        \n",
    "                    if (temp_value > optimal_value):\n",
    "                        optimal_value = temp_value\n",
    "                        action_space[row][col] = action\n",
    "                        \n",
    "                threshold = max (threshold ,  abs (optimal_value - state_values[row][col]))\n",
    "\n",
    "                state_values[row][col] = optimal_value\n",
    "        threshold_list.append(threshold)\n",
    "    \n",
    "    return (np.copy (state_values) , np.copy (threshold_list) , action_space)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this takes the action space and then return the correspoding policy\n",
    "def policy_evaluation (action_space):\n",
    "    value_space = np.zeros ((p_n , v_n))\n",
    "    for itr in range (10):\n",
    "        \n",
    "        if (itr % 10 == 0):\n",
    "            print (itr)\n",
    "        for row in range (p_n):\n",
    "            for col in range(v_n):\n",
    "                current_pos = positions[row]\n",
    "                current_vel = velocities[col]\n",
    "                action = action_space[row][col]\n",
    "                \n",
    "                new_pos , new_vel = mountain_car_simulation (current_pos , current_vel , action)\n",
    "                x , y = give_index(new_pos , new_vel)\n",
    "                \n",
    "                temp_value = value_space[x][y]\n",
    "                if (new_pos < 0.6):\n",
    "                    temp_value += -1\n",
    "                    \n",
    "                value_space[row][col] = temp_value\n",
    "    \n",
    "    return np.copy (value_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy (value_space):\n",
    "    policy = np.zeros ((p_n , v_n))\n",
    "    \n",
    "    for row in range(p_n):\n",
    "        for col in range(v_n):\n",
    "            optimal_values= np.zeros((0 , 1))\n",
    "            \n",
    "            current_pos = positions[row]\n",
    "            current_vel = velocities[col]\n",
    "            \n",
    "            \n",
    "            for action in [-1 , 0 , 1]:\n",
    "                new_pos , new_vel = mountain_car_simulation (current_pos , current_vel , action)\n",
    "                x , y = give_index (new_pos , new_vel)\n",
    "                temp_value = value_space[x][y]\n",
    "                \n",
    "                if (new_pos < 0.6):\n",
    "                    temp_value += -1\n",
    "                \n",
    "                optimal_values = np.vstack([optimal_values , np.array([temp_value])])\n",
    "            \n",
    "            \n",
    "            policy[row][col] = np.argmax (optimal_values)\n",
    "            \n",
    "    return np.copy (policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iteration ():\n",
    "    policy = np.zeros ((p_n , v_n))\n",
    "    value = np.zeros ((p_n , v_n))\n",
    "    \n",
    "    for itr in range(200):\n",
    "        print (\"Number of iterations : \" , itr)\n",
    "        value = policy_evaluation(policy)\n",
    "        policy = update_policy(value)\n",
    "        \n",
    "    return (value , policy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of iterations :  0\n",
      "number of iterations :  50\n",
      "number of iterations :  100\n",
      "number of iterations :  150\n",
      "number of iterations :  200\n",
      "number of iterations :  250\n",
      "number of iterations :  300\n",
      "number of iterations :  350\n",
      "number of iterations :  400\n",
      "number of iterations :  450\n",
      "number of iterations :  500\n",
      "number of iterations :  550\n",
      "number of iterations :  600\n",
      "number of iterations :  650\n"
     ]
    }
   ],
   "source": [
    "state_value = np.zeros ((p_n , v_n))\n",
    "final_values , threshold_list , action_space= value_iteration(state_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot (range(len(threshold_list)) , threshold_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "action_space = return_policy(final_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': '{: 0.5f}'.format})\n",
    "np.savetxt(\"value.txt\" , final_values , fmt = \"%0.5f\")\n",
    "np.savetxt(\"action.txt\" , action_space , fmt = \"%i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.set_printoptions(formatter={'float': '{: 0.5f}'.format})\n",
    "np.savetxt(\"value.txt\" , final_values , fmt = \"%0.5f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8 , 6))\n",
    "plt.imshow (final_values , cmap = \"hot\" , interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8 , 6))\n",
    "plt.imshow (action_space , cmap = \"hot\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (threshold_list[len(threshold_list) - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "value , policy = policy_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8 , 6))\n",
    "plt.imshow (value , cmap = \"hot\" , interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
